# **Setup Kubernetes (K8s) Cluster On-Premise**

![alt text](images/k8s-cluster.png)
![alt text](images/install-certs.png)
![alt text](images/kubeadm.png)

## **Prerequisites**

- **Hardware and network requirements**: Ensure that your machines meet the minimum resource requirements (e.g., CPU, RAM, storage) and have network connectivity.
- **Operating system setup**: Install a supported OS (e.g., Ubuntu 20.04 LTS) and ensure it is up-to-date.
- **User permissions and configurations**: Ensure you have sudo privileges to install and configure software.
- **Basic knowledge of Docker and container runtimes**: Familiarity with container concepts and tools like Docker will be helpful.

## **1. Give Hostname to Nodes** (Master and Worker Nodes)

### **Set Hostname for Node**

Setting the hostname for the master node to identify it in the cluster.

```bash
sudo hostnamectl set-hostname master-node
```

```bash
sudo hostnamectl set-hostname worker-node-1
```

```bash
sudo hostnamectl set-hostname worker-node-2
```

### **Update Hosts File**

Adding the IP address and hostname of each node to the `/etc/hosts` file.

```ini
 [master-node-private-ip] master-node
 [worker-node-1-private-ip] worker-node-1
 [worker-node-2-private-ip] worker-node-2
```

```ini
172.31.30.241 master-node
172.31.24.128 worker-node-1
172.31.30.246 worker-node-2
```

```ini
192.168.1.50 master-node
192.168.1.51 worker-node-1
192.168.1.52 worker-node-2
```

## **2. Environment Preparation** (Master and Worker Nodes)

### **Update and Install Dependencies (Both Master and Worker Nodes)**

Updating the system and installing necessary dependencies ensures that your system is ready for Kubernetes installation.

```bash
sudo apt-get update && sudo apt-get upgrade -y
sudo apt-get install -y apt-transport-https ca-certificates curl software-properties-common
```

### **Disable Swap (Both Master and Worker Nodes)**

Kubernetes requires swap to be disabled to ensure it has full control over memory management.

```bash
sudo swapoff -a

# verify that swap is off
free -h
```

#### Disable Swap Permanently (Optional)

1. **Open the `/etc/fstab` file:** This file contains entries that tell the operating system which partitions to mount automatically at startup and where. You'll need to find the line that refers to the swap space.

   ```bash
   sudo vim /etc/fstab
   ```

2. **Comment out the swap line:** Find the line that looks similar to:

   ```txt
   /dev/sdaX none swap sw 0 0
   ```

   Comment it out by adding a `#` at the beginning of the line, making it look like:

   ```txt
   #/dev/sdaX none swap sw 0 0
   ```

   Replace `/dev/sdaX` with the actual device identifier for your swap partition if it's different.

3. **Save the file and exit:** After commenting out the swap line, save the file and exit the editor.

4. **Turn off swap:** To ensure that swap is off without restarting, you can also run:

   ```bash
   sudo swapoff -a
   ```

5. **Reboot your machine:** After making these changes, reboot your machine to ensure the settings take effect and swap remains off:

   ```bash
   sudo reboot
   ```

## **3. Install [Container Runtime](https://kubernetes.io/docs/setup/production-environment/container-runtimes/)** (Master and Worker Nodes)

### **Enable IPv4 packet forwarding**

Enable IPv4 packet forwarding to allow containers to communicate with each other and the outside world.

```bash
# sysctl params required by setup, params persist across reboots
cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.ipv4.ip_forward = 1
EOF

# Apply sysctl params without reboot
sudo sysctl --system

# Verify that net.ipv4.ip_forward is set to 1 with:
sysctl net.ipv4.ip_forward
```

### **Install containerd**

`containerd` is an industry-standard core container runtime that manages the complete container lifecycle of its host system.

```bash
sudo apt-get update
sudo apt-get install -y containerd
```

### **Configure containerd**

Creating and editing the configuration file for containerd ensures it is set up correctly to work with Kubernetes.

```bash
sudo mkdir -p /etc/containerd
containerd config default | sudo tee /etc/containerd/config.toml
```

Edit the configuration file:

```bash
sudo vim /etc/containerd/config.toml
```

In the `[plugins.cri.containerd.runtimes.runc.options]` section, set `SystemdCgroup = true` to use systemd as the cgroup driver:

```ini
[plugins.cri.containerd.runtimes.runc.options]
  SystemdCgroup = true
```

### **Restart and Enable containerd**

Restarting and enabling containerd to start on boot.

```bash
sudo systemctl restart containerd
sudo systemctl enable containerd
sudo systemctl status containerd
```

## **4. Install [kubeadm and kubelet](https://v1-30.docs.kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/)** (Master and Worker Nodes)

this steps is for version 1.30

### **Add Kubernetes Repository**

#### **Install Required Packages**

```bash
sudo apt-get update
# apt-transport-https may be a dummy package; if so, you can skip that package
sudo apt-get install -y apt-transport-https ca-certificates curl gpg
```

#### **Add Kubernetes Repository Key**

```bash
# If the directory `/etc/apt/keyrings` does not exist, it should be created before the curl command, read the note below.
# sudo mkdir -p -m 755 /etc/apt/keyrings
curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.30/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
```

```bash
# This overwrites any existing configuration in /etc/apt/sources.list.d/kubernetes.list
echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.30/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list
```

### **Install Kubernetes Components**

Installing `kubelet` and `kubeadm` which are essential for managing Kubernetes.

```bash
sudo apt-get update

# Install specific versions of kubelet and kubeadm
# you can get version from => apt-cache madison kubeadm
# sudo apt-get install -y kubeadm=1.30.0-1.1 kubelet=1.30.0-1.1 kubectl=1.30.0-1.1
sudo apt-get install -y kubeadm kubelet kubectl

# prevent the packages from being updated automatically
sudo apt-mark hold kubeadm kubelet kubectl

# check the status of kubelet
sudo systemctl status kubelet
```

- **kubeadm**: A tool to bootstrap the Kubernetes cluster.
  - **on Master Nodes**: This is mandatory since kubeadm is responsible for setting up the control plane.
  - **on Worker Nodes Initially**: Itâ€™s necessary for the kubeadm join process to bring the worker node into the cluster. After the node is joined, you can choose to remove it.
- **kubelet**: The primary "node agent" that runs on each node.

## **5. Initialize the Kubernetes Control Plane** (Master Node Only)

Running `kubeadm init` initializes the control plane, setting up the master node.

```bash
sudo kubeadm init
```

```bash
sudo mkdir -p $HOME/.kube
sudo cp /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

# Verify the cluster status
kubectl cluster-info
```

## **6. Configure Required Ports** (Master and Worker Nodes)

### **Check [Required Ports](https://kubernetes.io/docs/reference/networking/ports-and-protocols/) for MasterNodes**

![alt text](images/control-plans-ports.png)

```bash
sudo ufw enable
```

```bash
# Allow required ports through the firewall
sudo ufw allow 6443/tcp
sudo ufw allow 2379:2380/tcp
sudo ufw allow 10250/tcp
sudo ufw allow 10257/tcp
sudo ufw allow 10259/tcp

sudo ufw allow 22/tcp
sudo ufw reload
```

### **Check Required Ports for WorkerNodes**

![alt text](images/worker-nodes-ports.png)

```bash

sudo ufw allow 10250/tcp
sudo ufw allow 10256/tcp
sudo ufw allow 30000:32767/tcp

sudo ufw allow 22/tcp
sudo ufw reload
```

## **7. Install a Pod [Network Add-on](https://kubernetes.io/docs/concepts/cluster-administration/addons//)** (Worker Nodes Only)

### **Install [Calico](https://docs.tigera.io/calico/latest/getting-started/kubernetes/quickstart) Network Plugin**

```bash
# 1. Install the Tigera Calico operator and custom resource definitions.
kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.28.1/manifests/tigera-operator.yaml
```

```bash
# download the custom resource definitions
wget https://raw.githubusercontent.com/projectcalico/calico/v3.28.1/manifests/custom-resources.yaml -O calico.yaml
```

```bash
# 3. edit cidr in calico.yaml by using your network VPC CIDR (e.g., 1
sudo vim calico.yaml
```

```bash
# 4. Apply the custom resource definitions.
kubectl apply -f calico.yaml
```

```bash
kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml
```

```bash
# 5. Verify that all the pods are running.
kubectl get pods -n calico-system
```

### **Install [Cilium](https://docs.cilium.io/en/stable/gettingstarted/k8s-install-default/#install-the-cilium-cli) Network Plugin**

```bash
# 1. Install the Cilium CLI
CILIUM_CLI_VERSION=$(curl -s https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt)
CLI_ARCH=amd64
if [ "$(uname -m)" = "aarch64" ]; then CLI_ARCH=arm64; fi
curl -L --fail --remote-name-all https://github.com/cilium/cilium-cli/releases/download/${CILIUM_CLI_VERSION}/cilium-linux-${CLI_ARCH}.tar.gz{,.sha256sum}
sha256sum --check cilium-linux-${CLI_ARCH}.tar.gz.sha256sum
sudo tar xzvfC cilium-linux-${CLI_ARCH}.tar.gz /usr/local/bin
rm cilium-linux-${CLI_ARCH}.tar.gz{,.sha256sum}
```

```bash
# 2. Install Cilium
cilium install --version 1.16.1
```

```bash
# 3. Verify Installation
cilium status --wait
cilium connectivity test
```

## **8. Join Worker Nodes to the Cluster** (Worker Nodes Only)

### **Generate Join Command on Master Node**

Getting the join command to add worker nodes to the cluster.

```bash
kubeadm token create --print-join-command
```

### **Execute Join Command on Worker Nodes**

Running the join command on worker nodes to connect them to the cluster.

## **9. Verify Cluster Setup** (Remote Node)

### **Check Nodes Status**

Verifying that all nodes are successfully joined to the cluster.

```bash
kubectl get nodes
```

### **Verify Pod Network**

Ensuring the network setup is correct and pods are communicating.

```bash
kubectl get pods --all-namespaces

kubectl run test1 --image=nginx
kubectl run test2 --image=nginx
```

## **Conclusion**

- **Summary of steps**: Recap of the process from preparation to verification.
- **Additional resources**: Links and references for further learning about Kubernetes and container runtimes.

---

### **Recommended Number of Nodes:**

- **Master Nodes**: For a production cluster, it is recommended to have at least 3 master nodes for high availability.
- **Worker Nodes**: Start with at least 2-3 worker nodes to ensure load distribution and fault tolerance.

This detailed guide specifies which steps are for the master node, which are for the worker nodes, and which are common to both, ensuring clarity and understanding at each stage of the setup process.
