# LoadBalancer

In Kubernetes, a `LoadBalancer` type service provides a mechanism to expose your applications to external traffic. It is often used to distribute traffic across multiple nodes and pods. This type of service integrates with the cloud provider's external load balancing feature (like AWS Elastic Load Balancer, GCP Load Balancer, or Azure Load Balancer) to manage traffic. Here’s a step-by-step explanation of how `LoadBalancer` works in a Kubernetes cluster with multiple nodes:

## **Service of Type `LoadBalancer`**

When you create a service of type `LoadBalancer`, Kubernetes asks the cloud provider to provision an external load balancer (such as AWS ELB, GCP Load Balancer, etc.). This external load balancer will distribute incoming traffic to your Kubernetes nodes and subsequently to the pods running the application.

## **Multi-Node Setup**

Imagine you have a Kubernetes cluster with three nodes (Node A, Node B, and Node C) and multiple pods spread across these nodes.

- **Node A**: Hosts 2 pods of the application
- **Node B**: Hosts 1 pod of the application
- **Node C**: Hosts 1 pod of the application

Each node has multiple pods, and those pods are part of the service that you’ve exposed using the `LoadBalancer`.

## **How Load Balancing Works with Multi-Node Setup**

Let’s walk through the flow of traffic:

### Step 1: **User Traffic Hits the External Load Balancer**

- When a user accesses the application (e.g., via `http://<external-ip>`), the traffic first hits the **external load balancer** provisioned by the cloud provider.

- The external load balancer has an **external IP address** and listens for incoming traffic. This IP is managed by the cloud provider and is publicly accessible.

### Step 2: **Load Balancer Forwards Traffic to Kubernetes Nodes**

- The external load balancer distributes the incoming traffic across the **Kubernetes nodes** (Node A, Node B, Node C).

- The external load balancer doesn't forward traffic directly to the pods; instead, it forwards traffic to the **Kubernetes nodes** based on the cloud provider's load balancing algorithm (e.g., round-robin, least connections, etc.).

### Step 3: **Traffic Hits the Service on the Node**

- When the traffic reaches a node (e.g., Node A), the **Kubernetes service** takes over. The service knows about all the pods running the application, and it uses its internal load balancing mechanism to forward traffic to one of the pods.

- For instance, if traffic hits Node A, the service might direct the traffic to one of the two pods running on Node A.

### Step 4: **Pod Selection Using Kube-Proxy**

- The **kube-proxy** on each node is responsible for directing traffic to the appropriate pod. It uses the service's endpoints (a list of all the pods that are part of the service) to forward the request to a pod.

- Kube-proxy can use different load balancing algorithms (like round-robin) to distribute traffic among the pods. For example, traffic coming into Node A could be forwarded to either of the pods on that node or, if necessary, redirected to a pod on another node.

## **Internal Load Balancing Between Pods**

Each node will have its kube-proxy service running, which is responsible for handling traffic forwarding at the node level. Here’s how this works:

- **Round-robin or IP Hashing**: Once the traffic reaches the node, kube-proxy uses an algorithm (such as round-robin) to distribute the traffic among the pods. If traffic is directed to Node A, but Node A has overloaded pods, kube-proxy might forward the request to a pod on Node B or Node C if necessary.

- **End-to-End Load Balancing**: The external load balancer spreads traffic across nodes, while kube-proxy within the node balances the traffic among the pods.

## **Example of a Load Balancer Flow**

Let’s assume you’ve set up a service with the following structure:

- 4 pods of the service spread across 3 nodes:
  - Node A: Pod 1, Pod 2
  - Node B: Pod 3
  - Node C: Pod 4

Here’s how traffic flows:

1. **User Traffic**: A user sends a request to the external IP of the service, which points to the external load balancer (e.g., `http://123.45.67.89`).

2. **External Load Balancer**: The cloud load balancer receives the request and forwards it to one of the nodes based on its algorithm (e.g., round-robin).

3. **Node Selection**: The external load balancer selects Node A.

4. **Kubernetes Service and Kube-Proxy**:

   - On Node A, the kube-proxy receives the traffic.
   - The kube-proxy checks the list of available pods in the service's endpoints and forwards the request to Pod 1 or Pod 2 (using round-robin or IP hashing).

5. **Request to Pods**: If traffic on Node A's pods is heavy, kube-proxy may forward the request to a pod on Node B or Node C.

## **Disadvantages of Using Only `LoadBalancer` Type**

When you use the `LoadBalancer` type service alone in Kubernetes, you can face several disadvantages:

- **Multiple Load Balancers**: For each service you expose via `LoadBalancer`, Kubernetes provisions a separate external load balancer. This can become expensive if you have many services in your cluster, especially in cloud environments where load balancers are billed individually.

- **Limited Routing Flexibility**: A `LoadBalancer` type service only directs traffic to a specific service. It doesn't provide advanced routing capabilities, such as path-based routing (i.e., routing requests based on the URL path) or host-based routing (i.e., routing based on the hostname).

- **No Centralized Traffic Management**: Each service will have its own load balancer, which can lead to a lack of centralized control and complexity in managing multiple load balancers and external IPs.

## **Why Ingress + Load Balancer is a Better Approach**

Using an **Ingress** with a `LoadBalancer` type service can help overcome these disadvantages:

- **Single External Load Balancer**: Instead of provisioning a separate load balancer for each service, you can use a single `LoadBalancer` for the ingress controller. The ingress controller acts as a traffic manager and routes requests to different services based on path or host rules.

- **Advanced Routing**: Ingress enables features like path-based or host-based routing, which allows you to direct traffic to different services based on request URLs or domains.

- **Cost Efficiency**: You can expose multiple services using a single external load balancer and ingress, which significantly reduces costs.

## Summary

- A **`LoadBalancer` service** provisions an external load balancer that distributes traffic across multiple nodes and pods in a Kubernetes cluster.
- In a **multi-node setup**, traffic first hits the external load balancer, which forwards it to one of the Kubernetes nodes. The **kube-proxy** on the node then forwards the traffic to the appropriate pod.
- The **disadvantage** of using only the `LoadBalancer` service type is the cost and lack of advanced traffic routing capabilities.
- **Ingress** solves this by enabling advanced routing (like path-based or hostname-based routing) while still using a single load balancer, making it more cost-effective and flexible.
