# K8s Service

In Kubernetes, a Service is an **object** that facilitates communication and access to a set of Pods. Here's a brief overview:

![alt text](images/service-selector.gif)
![alt text](images/service-endpoints.jpg)
- It is a Kubernetes API object that defines a logical set of Pods and a policy to access them. It abstracts the underlying Pods and provides a stable endpoint for network communication.

- The Service object, like other Kubernetes objects, is stored in `etcd`, the distributed key-value store that holds the cluster's state. This allows Kubernetes to persist and manage the Service's configuration and status.

## **Purpose:**

- **Service Discovery:** Provides a stable DNS name and IP address to access a set of Pods, which can change dynamically.
- **Load Balancing:** Distributes traffic across the Pods that match the Service’s selector.
- **Networking:** Manages network rules and configurations to ensure that traffic is correctly routed to the appropriate Pods.

## **Types of Services:**

- **ClusterIP:** Exposes the Service on an internal IP address within the cluster (default type).
- **NodePort:** Exposes the Service on a static port on each node’s IP address, allowing external access.
- **LoadBalancer:** Creates an external load balancer (typically cloud provider-specific) to distribute traffic to the Service.
- **ExternalName:** Maps the Service to an external DNS name.

## Lifecycle of Creating a ClusterIP Service

![alt text](images/service-cluster-ip-0.png)
![alt text](images/service-cluster-ip-1.png)
![alt text](images/service-cluster-ip-2.png)

### **Step 1: Service Definition and Creation**

#### **a. Writing the Service Manifest:**

- You start by defining the service in a YAML or JSON file. This file includes:
  - `kind: Service`
  - `metadata`: The name and labels for the service.
  - `spec.type: ClusterIP` (optional because ClusterIP is the default type).
  - `spec.selector`: A set of labels used to identify the pods this service will manage.
  - `spec.ports`: The ports that the service will expose.

Example YAML:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app: my-app
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8080
```

#### **b. Submitting the Service Manifest:**

- Use the command `kubectl apply -f service.yaml` to submit the service definition to the Kubernetes API server.
- The API server processes the request:
  - **Validation:** Checks the service manifest for correctness.
  - **Creation:** If valid, the API server creates the Service object in the cluster.

#### **c. Storing the Service in etcd:**

- The API server stores the Service object in `etcd`, the distributed key-value store that holds the entire state of the Kubernetes cluster.
- **ClusterIP Assignment:** The API server allocates a unique ClusterIP from the cluster’s service IP range (e.g., `10.96.0.0/12` by default). This ClusterIP is stored in the Service object.

### **Step 2: Endpoint Discovery and Management**

#### **a. Selector Matching:**

- The API server looks for pods that match the labels specified in the service’s selector. For example, if the service’s selector is `app: my-app`, it finds all pods with this label.
- **Pod IPs:** The API server gathers the IP addresses of the matching pods.

#### **b. Creating the Endpoints Object:**

- The API server creates an Endpoints object, which lists the IP addresses and ports of the pods that match the service’s selector.
- This Endpoints object is linked to the Service object and stored in `etcd`.

Example Endpoints object:

```yaml
apiVersion: v1
kind: Endpoints
metadata:
  name: my-service
subsets:
  - addresses:
      - ip: 10.244.1.5
      - ip: 10.244.2.3
    ports:
      - port: 8080
```

### **Step 3: kube-proxy Configuration**

#### **a. kube-proxy Monitoring:**

- `kube-proxy` runs on every node in the cluster and continuously monitors the Kubernetes API for changes to Service and Endpoints objects.
- When a new service is created or endpoints change (e.g., new pods are added or removed), kube-proxy receives these updates.

#### **b. Setting Up Network Rules:**

- **iptables Mode:**

  - `kube-proxy` sets up `iptables` rules that map the service’s ClusterIP to the pod IPs listed in the Endpoints object.
  - These rules use DNAT (Destination NAT) to change the destination IP of incoming packets from the service’s ClusterIP to one of the pod IPs.

- **IPVS Mode:**
  - In IPVS mode, `kube-proxy` configures IPVS (IP Virtual Server) rules in the Linux kernel.
  - IPVS provides more efficient load balancing and supports different algorithms (e.g., round-robin, least connections).

### **Step 4: Simplified Traffic Flow and Load Balancing**

#### **1. Request Lifecycle from Pod to Service:**

The requesting pod sends traffic to the service's ClusterIP, `kube-proxy` intercepts this traffic and forwards it to one of the backend pods that the service manages.

##### **a. Pod Sends a Request to the Service:**

- **DNS Resolution:** A pod wants to communicate with a service, so it uses the service's name (e.g., `my-service`) to resolve the service's IP address (ClusterIP) using Kubernetes DNS.
- **Getting the ClusterIP:** The DNS lookup returns the ClusterIP (e.g., `10.96.0.1`), which is a stable IP address within the cluster that represents the service.

##### **b. Traffic is Routed to the Service's Pods:**

- **Pod Sends Traffic:** The pod sends its request to the ClusterIP and the port defined in the service (e.g., `10.96.0.1:80`).
- **kube-proxy Intercepts Traffic:**
  - **iptables Mode:** If `kube-proxy` is using iptables, it has set up rules that intercept the traffic to the ClusterIP. The rule changes the destination IP from the ClusterIP to one of the IP addresses of the pods selected by the service.
  - **IPVS Mode:** If `kube-proxy` is using IPVS, it similarly intercepts the traffic and routes it to one of the backend pod IPs, but it can use more sophisticated load balancing methods (like round-robin or least connections).
- **Traffic Reaches the Pod:** The traffic is forwarded to one of the pods that the service is targeting, based on the load balancing rules.

#### **2. Response Lifecycle from Service to Pod:**

The selected pod processes the request and sends the response directly back to the original requesting pod without passing through the service again.

##### **a. Pod Processes the Request:**

- **Pod Receives the Request:** The selected pod receives the request and processes it, performing whatever action or computation is required.

##### **b. Pod Sends a Response Back to the Original Pod:**

- **Direct Response Path:** The response is sent directly back to the pod that initiated the request. This happens because the original request contains the source IP of the requesting pod.
- **No Service Interception:** The response traffic does not go back through the service (ClusterIP) or `kube-proxy`. Instead, it is sent directly from the responding pod to the source pod using the source IP in the original request.
- **Response Delivered:** The requesting pod receives the response, completing the communication cycle.

### **Step 5: Handling Changes in the Service**

#### **a. Dynamic Endpoint Management:**

- As pods are added or removed from the cluster, the list of endpoints associated with the service changes.
- The API server updates the Endpoints object, and `kube-proxy` adjusts its network rules accordingly.

#### **b. Failover and Load Balancing:**

- If a pod fails or is terminated, `kube-proxy` stops routing traffic to that pod, ensuring that requests are only sent to healthy pods.

### **Step 6: Service Deletion**

#### **a. Removing the Service:**

- When you delete the service using `kubectl delete service my-service`, the API server removes the Service and Endpoints objects from `etcd`.
- `kube-proxy` detects the deletion and cleans up the corresponding network rules (iptables or IPVS) from all nodes.

#### **b. ClusterIP Release:**

- The ClusterIP assigned to the service is released back into the pool of available IPs, making it available for future services.

## Lifecycle of Creating a NodePort Service

![alt text](images/service-node-port-1.png)
![alt text](images/service-node-port-2.png)

1. **Service Definition and Creation**

   - **a. Writing the Service Manifest:**

     - Define the service in YAML or JSON with `kind: Service`, metadata, `spec.type: NodePort`, `spec.selector`, and `spec.ports`.
     - Example YAML:

       ```yaml
       apiVersion: v1
       kind: Service
       metadata:
         name: my-nodeport-service
       spec:
         type: NodePort
         selector:
           app: my-app
         ports:
           - protocol: TCP
             port: 80
             targetPort: 8080
             nodePort: 30000
       ```

   - **b. Submitting the Service Manifest:**

     - Use `kubectl apply -f service.yaml` to submit the service definition to the Kubernetes API server.
     - The API server processes the request:
       - **Validation:** Checks the service manifest for correctness.
       - **Creation:** If valid, the API server creates the Service object in the cluster.

   - **c. Storing the Service in etcd:**
     - The API server stores the Service object in `etcd`, including the `NodePort` type and any relevant service details.

2. **Service Configuration and Network Setup**

   - **a. Allocating the NodePort:**

     - If a `nodePort` is not specified in the manifest, Kubernetes automatically allocates one from the default range (30000-32767).
     - The API server assigns this port number and updates the Service object in `etcd`.

   - **b. Creating the Endpoints Object:**

     - The API server looks for pods matching the service’s selector (e.g., `app: my-app`) and gathers their IP addresses.
     - It creates an Endpoints object that lists these IPs and ports.
     - Example Endpoints object:

       ```yaml
       apiVersion: v1
       kind: Endpoints
       metadata:
         name: my-nodeport-service
       subsets:
         - addresses:
             - ip: 10.244.1.5
             - ip: 10.244.2.3
           ports:
             - port: 8080
       ```

3. **kube-proxy Configuration**

   - **a. kube-proxy Monitoring:**

     - `kube-proxy` runs on every node and monitors the Kubernetes API for changes to Service and Endpoints objects.
     - When a NodePort service is created or updated, `kube-proxy` receives these updates.

   - **b. Setting Up Network Rules:**

     - **iptables Mode:**

       - `kube-proxy` sets up `iptables` rules to route traffic from the allocated NodePort to the service’s ClusterIP.
       - It also sets up rules to perform DNAT (Destination NAT) so that incoming traffic on the NodePort is directed to the service’s ClusterIP and then to the backend pods.

     - **IPVS Mode:**
       - If using IPVS mode, `kube-proxy` sets up IPVS rules for routing traffic from the NodePort to the backend pods.

4. **Simplified Traffic Flow**

   - **a. Request Lifecycle from External Client to Service:**

     - **External Access:** An external client sends traffic to any node’s IP address and the allocated NodePort (e.g., `NodeIP:30000`).
     - **kube-proxy Routing:** `kube-proxy` on the node with the NodePort intercepts this traffic and routes it to the ClusterIP of the service.
     - **Service Routing:** The service forwards the traffic to one of the backend pods based on its load balancing rules.

   - **b. Response Lifecycle from Pod to External Client:**
     - **Pod Processes Request:** The selected pod processes the request and generates a response.
     - **Direct Response:** The response is sent directly back to the external client via the NodePort, without passing through the service again.

5. **Handling Changes in the Service**

   - **a. Dynamic Endpoint Management:**

     - As pods are added or removed, the API server updates the Endpoints object.
     - `kube-proxy` adjusts its network rules to route traffic to the updated list of backend pods.

   - **b. Failover and Load Balancing:**
     - If a pod fails or is terminated, `kube-proxy` stops routing traffic to that pod, ensuring requests are only sent to healthy pods.

6. **Service Deletion**

   - **a. Removing the Service:**

     - When you delete the service using `kubectl delete service my-nodeport-service`, the API server removes the Service and Endpoints objects from `etcd`.
     - `kube-proxy` detects the deletion and cleans up the corresponding network rules (iptables or IPVS) from all nodes.

   - **b. NodePort Release:**
     - The NodePort is released back into the pool of available ports, making it available for future services.

## Lifecycle of Creating a LoadBalancer Service

![alt text](images/service-load-balancer.png)

1. **Service Definition and Creation**

   - **a. Writing the Service Manifest:**

     - Define the service in YAML or JSON with `kind: Service`, metadata, `spec.type: LoadBalancer`, `spec.selector`, and `spec.ports`.
     - Example YAML:

       ```yaml
       apiVersion: v1
       kind: Service
       metadata:
         name: my-loadbalancer-service
       spec:
         type: LoadBalancer
         selector:
           app: my-app
         ports:
           - protocol: TCP
             port: 80
             targetPort: 8080
       ```

   - **b. Submitting the Service Manifest:**

     - Use `kubectl apply -f service.yaml` to submit the service definition to the Kubernetes API server.
     - The API server processes the request:
       - **Validation:** Checks the service manifest for correctness.
       - **Creation:** If valid, the API server creates the Service object in the cluster.

   - **c. Storing the Service in etcd:**
     - The API server stores the Service object in `etcd`, including the `LoadBalancer` type and any relevant service details.

2. **Load Balancer Provisioning**

   - **a. Provisioning by Cloud Provider:**

     - When a `LoadBalancer` service is created, Kubernetes communicates with the cloud provider’s API (e.g., AWS ELB, GCP Load Balancer) to provision a load balancer.
     - **Cloud Controller Manager (CCM):**
       - The Cloud Controller Manager (CCM) in the Kubernetes cluster is responsible for interacting with the cloud provider to create the load balancer.
       - The CCM sends a request to the cloud provider to create a new load balancer and configure it with the necessary settings (e.g., listeners, target groups).

   - **b. Load Balancer Allocation:**
     - The cloud provider allocates a public IP address for the load balancer and configures it to forward traffic to the Kubernetes cluster.

3. **Service Configuration and Network Setup**

   - **a. Creating the Endpoints Object:**

     - The API server looks for pods that match the service’s selector (e.g., `app: my-app`) and gathers their IP addresses.
     - It creates an Endpoints object that lists these IPs and ports.
     - Example Endpoints object:

       ```yaml
       apiVersion: v1
       kind: Endpoints
       metadata:
         name: my-loadbalancer-service
       subsets:
         - addresses:
             - ip: 10.244.1.5
             - ip: 10.244.2.3
           ports:
             - port: 8080
       ```

4. **Load Balancer Configuration**

   - **a. Configuring Load Balancer Rules:**

     - The cloud provider configures the load balancer with rules to forward traffic from the public IP to the service’s ClusterIP.
     - **Listeners:** The load balancer sets up listeners on the specified port (e.g., port 80) to handle incoming traffic.
     - **Target Groups:** The load balancer routes traffic to the target group of backend pods based on the Endpoints object.

   - **b. Updating DNS:**
     - The load balancer is assigned a public DNS name or IP address, which is updated in the Service object’s status field.
     - The Service object in Kubernetes is updated with this public address, making it available for external clients.

5. **Simplified Traffic Flow**

   - **a. Request Lifecycle from External Client to Service:**

     - **External Access:** An external client sends traffic to the load balancer’s public IP or DNS name.
     - **Load Balancer Routing:** The load balancer forwards this traffic to one of the backend pods based on its configuration and load balancing rules.
     - **Service Routing:** The service forwards the traffic to the appropriate backend pod(s) based on the load balancing rules and the Endpoints object.

   - **b. Response Lifecycle from Pod to External Client:**
     - **Pod Processes Request:** The selected pod processes the request and generates a response.
     - **Direct Response:** The response is sent back to the external client via the load balancer, which handles the return path.

6. **Handling Changes in the Service**

   - **a. Dynamic Endpoint Management:**

     - As pods are added or removed, the API server updates the Endpoints object.
     - The cloud provider updates the load balancer’s configuration to include or exclude backend pods accordingly.

   - **b. Failover and Load Balancing:**
     - If a pod fails or is terminated, the load balancer stops routing traffic to that pod, ensuring requests are only sent to healthy pods.

7. **Service Deletion**

   - **a. Removing the Service:**

     - When you delete the service using `kubectl delete service my-loadbalancer-service`, the API server removes the Service and Endpoints objects from `etcd`.
     - The Cloud Controller Manager (CCM) communicates with the cloud provider to delete the load balancer and release the public IP address.

   - **b. Clean-Up:**
     - The cloud provider cleans up any associated resources (e.g., listeners, target groups) and releases the public IP address.

## Summary

a Service in Kubernetes is an object stored in `etcd` that provides network access and load balancing to a set of Pods, abstracting their dynamic nature and ensuring reliable communication.
