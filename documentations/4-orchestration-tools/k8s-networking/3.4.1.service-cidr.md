# Service CIDR in Kubernetes

Understanding the Service CIDR (Classless Inter-Domain Routing) in Kubernetes is essential for managing the networking aspects of your cluster. This guide covers:

1. **Who Manages Service CIDR and How**
1. **How to Get Service CIDR**
1. **How to Update Service CIDR**

## 1. Who Manages Service CIDR and How

### **Management by kube-apiserver**

The **kube-apiserver** is the central component responsible for managing the Service CIDR and assigning ClusterIPs to Services.

#### **How It Works:**

1. **Service CIDR Configuration:**

   - The Service CIDR is specified when starting the kube-apiserver using the `--service-cluster-ip-range` parameter.

     ```bash
     kube-apiserver --service-cluster-ip-range=<service-cidr>
     ```

2. **ClusterIP Allocation:**

   - When you create a Service without specifying a `clusterIP`, the kube-apiserver assigns an available IP from the Service CIDR.

   - **Example:**

     ```yaml
     apiVersion: v1
     kind: Service
     metadata:
       name: my-service
     spec:
       selector:
         app: MyApp
       ports:
         - protocol: TCP
           port: 80
           targetPort: 9376
     ```

     - The kube-apiserver assigns a `clusterIP` like `10.96.0.5`.

3. **IP Allocation Management:**

   - The kube-apiserver uses an internal IP allocator to keep track of assigned and available IPs within the Service CIDR range.

   - This allocator ensures unique IP assignment and prevents conflicts.

### **Role of kube-proxy**

- **kube-proxy** uses the Service definitions and associated ClusterIPs to configure the networking rules on each node.

- It ensures that traffic destined for a Service's ClusterIP is correctly routed to one of its backing Pods.

### **Configuration and Maintenance**

#### **Initial Configuration:**

- The Service CIDR is set during cluster initialization and remains constant unless explicitly changed.

#### **Updating Service CIDR:**

- Requires updating the kube-apiserver configuration and restarting it.
- All components that rely on the Service CIDR (like kube-proxy and CoreDNS) need to be updated accordingly.

### **Managed Kubernetes Services**

In managed services like GKE, EKS, and AKS, the Service CIDR is usually specified during cluster creation.

#### **Management by Cloud Provider:**

- The cloud provider manages the kube-apiserver and networking components.
- Changing the Service CIDR often involves recreating the cluster.

### **Why kube-apiserver Manages Service CIDR**

#### **Centralized Control:**

- The kube-apiserver acts as the brain of the cluster, making it logical for it to manage IP allocation.

#### **Consistency:**

- Central management ensures that all Services across the cluster have unique and consistent ClusterIPs.

#### **Simplification:**

- Users do not need to manage ClusterIP assignments manually, reducing the potential for errors.

## 2. How to Get Service CIDR

The Service CIDR is the IP range from which Kubernetes assigns Cluster IPs to Services. Here's how you can find out what Service CIDR your cluster is using

### **Method 1: Check kube-apiserver Configuration**

The most reliable way is to check the kube-apiserver's `--service-cluster-ip-range` parameter.

#### 1. **Access the Control Plane Node:**

SSH into the control plane node where the kube-apiserver is running.

```bash
ssh user@control-plane-node
```

#### 2. **Locate the kube-apiserver Manifest File:**

For clusters set up using **kubeadm**, the manifest is usually located at:

```bash
/etc/kubernetes/manifests/kube-apiserver.yaml
```

#### 3. **Inspect the Manifest File:**

Use a text editor or `grep` to find the `--service-cluster-ip-range` parameter.

```bash
cat /etc/kubernetes/manifests/kube-apiserver.yaml | grep service-cluster-ip-range
```

**Example Output:**

```yaml
- --service-cluster-ip-range=10.96.0.0/12
```

The value `10.96.0.0/12` is your Service CIDR.

### **Method 2: Infer from Existing Services**

If you cannot access the control plane node, you can infer the Service CIDR by examining the Cluster IPs of existing Services.

#### 1. **List All Services and Their Cluster IPs:**

```bash
kubectl get svc --all-namespaces -o wide
```

#### 2. **Analyze the Cluster IPs:**

- Observe the range and subnet of the Cluster IPs assigned to the Services.
- While this method may not provide the exact CIDR, it can give you an approximate idea.

- **Example:**

  If most Cluster IPs are in the range `10.96.x.x`, the Service CIDR might be `10.96.0.0/12`.

### **Method 3: Check Kubernetes Configuration Files**

You can also check configuration files for hints about the Service CIDR.

#### 1. **Inspect kube-proxy ConfigMap:**

```bash
kubectl -n kube-system get configmap kube-proxy -o yaml
```

Look for any mention of `clusterCIDR` or Service CIDR settings.

#### 2. **Review Cluster Creation Files:**

If you used a tool like **kubeadm** to set up the cluster, check the `ClusterConfiguration` file used during initialization.

```bash
cat kubeadm-config.yaml | grep serviceSubnet
```

**Example Output:**

```yaml
serviceSubnet: 10.96.0.0/12
```

### **Note on Managed Kubernetes Services**

In managed Kubernetes services (e.g., GKE, EKS, AKS), you might not have access to the kube-apiserver configuration. In such cases, refer to the cloud provider's documentation or use their CLI tools to retrieve the Service CIDR

## 3. How to Update Service CIDR

Changing the Service CIDR in an existing Kubernetes cluster is a complex task that can cause disruptions. Here are two approaches to accomplish this:

### **Approach 1 (Complex): Modify the Existing Cluster**

**Warning:** This method involves several steps and may lead to service downtime. Proceed with caution and consider performing these actions during a maintenance window.

#### **Steps:**

1. **Update kube-apiserver Configuration:**

   - **Edit the kube-apiserver Manifest File:**

     ```bash
     sudo vi /etc/kubernetes/manifests/kube-apiserver.yaml
     ```

   - **Change the `--service-cluster-ip-range` Parameter:**

     ```yaml
     - --service-cluster-ip-range=<new-service-cidr>
     ```

2. **Restart kube-apiserver:**

   - Saving the manifest file will automatically restart the kube-apiserver if it's running as a static pod.

3. **Update kube-proxy Configuration:**

   - **Edit the kube-proxy ConfigMap:**

     ```bash
     kubectl -n kube-system edit configmap kube-proxy
     ```

   - **Update `clusterCIDR` (if present):**

     ```yaml
     clusterCIDR: <new-service-cidr>
     ```

4. **Restart kube-proxy Pods:**

   - Delete existing kube-proxy pods to reload the new configuration.

     ```bash
     kubectl -n kube-system delete pods -l k8s-app=kube-proxy
     ```

5. **Recreate ClusterIP Services:**

   - Existing Services will still have ClusterIPs from the old CIDR range.
   - **Delete and Recreate Services:**

     ```bash
     kubectl delete svc <service-name>
     kubectl apply -f <service-definition.yaml>
     ```

6. **Restart DNS Pods:**

   - Restart CoreDNS to ensure DNS services pick up the new CIDR.

     ```bash
     kubectl -n kube-system rollout restart deployment coredns
     ```

7. **Verify the Changes:**

   - Ensure Services have ClusterIPs from the new CIDR.

     ```bash
     kubectl get svc --all-namespaces
     ```

   - Test inter-service communication.

### **Approach 2 (Safer): Recreate the Cluster**

This method involves creating a new cluster with the desired Service CIDR and migrating your workloads.

#### **Steps:**

1. **Backup Existing Resources:**

   - **Export All Resources:**

     ```bash
     kubectl get all --all-namespaces -o yaml > all-resources-backup.yaml
     ```

   - **Note:** This command exports Deployments, Services, Pods, etc.

2. **Create a New Cluster with the Desired CIDR:**

   - **For kubeadm:**

     ```bash
     kubeadm init --service-cidr=<new-service-cidr> [other options]
     ```

   - **For Managed Services:**

     - Use the provider's tools to create a new cluster, specifying the new Service CIDR.

3. **Restore Resources to the New Cluster:**

   - **Apply the Backup File:**

     ```bash
     kubectl apply -f all-resources-backup.yaml
     ```

   - **Adjust Configurations if Necessary:**

     - Update any cluster-specific configurations in the YAML files before applying.

4. **Validate the New Cluster:**

   - Ensure all resources are running correctly.
   - Verify that Services have ClusterIPs from the new CIDR.

5. **Decommission the Old Cluster:**

   - Once the new cluster is operational, safely decommission the old cluster.

### **Recommendation**

- **Approach 2** is generally safer and cleaner, especially for production environments.
- **Approach 1** should only be used if recreating the cluster is not feasible.

## **Summary**

- **Getting Service CIDR:**

  - Best obtained by checking the kube-apiserver configuration.
  - Can be inferred from existing Services if necessary.

- **Updating Service CIDR:**

  - **Approach 1:** Modify the existing cluster, which is complex and risky.
  - **Approach 2:** Recreate the cluster with the new CIDR, which is safer and recommended.

- **Management of Service CIDR:**

  - Managed by the kube-apiserver, which assigns ClusterIPs to Services.
  - Relies on internal mechanisms to track and allocate IP addresses.
